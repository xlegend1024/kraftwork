{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try-it 8.1: The \"Best\" Model\n",
    "\n",
    "This module was all about regression and using Python's scikitlearn library to build regression models.  Below, a dataset related to real estate prices in California is given. While many of the assignments you have built and evaluated different models, it is important to spend some time interpreting the resulting \"best\" model.  \n",
    "\n",
    "\n",
    "Your goal is to build a regression model to predict the price of a house in California.  After doing so, you are to *interpret* the model.  There are many strategies for doing so, including some built in methods from scikitlearn.  One example is `permutation_importance`.  Permutation feature importance is a strategy for inspecting a model and its features importance.  \n",
    "\n",
    "Take a look at the user guide for `permutation_importance` [here](https://scikit-learn.org/stable/modules/permutation_importance.html).  Use  the `sklearn.inspection` modules implementation of `permutation_importance` to investigate the importance of different features to your regression models.  Share these results on the discussion board."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install interpret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import make_column_transformer, make_column_selector\n",
    "from sklearn.preprocessing import OneHotEncoder, PolynomialFeatures, OrdinalEncoder\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cali = pd.read_csv('data/housing.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cali.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cali.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Qucik EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cali.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`total_bedrooms` has 207 missing values (1% of data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cali[\"total_bedrooms\"].plot.box()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the missing values are around 1%, drop rows that has missing rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Shape before drop NaN {cali.shape}\")\n",
    "cali = cali.dropna()\n",
    "print(f\"After before drop NaN {cali.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Closer to ocean greater house value\n",
    "\n",
    "> Order of the ocean_proximity category will follows the order of mean of house value by the proximity group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(cali[\"ocean_proximity\"].value_counts().index.to_list())\n",
    "ocean_proximity_category = [cali.groupby([\"ocean_proximity\"]).mean()[\"median_house_value\"].sort_values(ascending=True).index.to_list()]\n",
    "cali.groupby([\"ocean_proximity\"]).mean()[\"median_house_value\"].sort_values(ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ocean_proximity_category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cali.corr()[[\"median_house_value\"]].nlargest(columns=\"median_house_value\", n = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`median_income` has the hightest correlation wtih `median_house_vale`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = cali.sample(n = 1000)\n",
    "plt.scatter(cali[\"median_income\"], cali[\"median_house_value\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get base line model\n",
    "\n",
    "Use `Lineare Regression' model to predict \n",
    "\n",
    "Use numeric features, exclude categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = ''\n",
    "best_mse = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelName = \"median_house_value\"\n",
    "features = cali.drop([labelName], axis=1)\n",
    "numericFeatures = features.select_dtypes(include=\"number\")\n",
    "categoricalFeatures = features.select_dtypes(include=\"object\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"numeric features: \", numericFeatures.columns)\n",
    "print(\"categorical featuer: \", categoricalFeatures.columns)\n",
    "print(\"label: \", labelName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_base = cali[numericFeatures.columns]\n",
    "y_base = cali[labelName]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_base, y_base, test_size=0.3, random_state=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = Pipeline([\n",
    "    (\"lr\", LinearRegression())\n",
    "]).fit(X_base, y_base)\n",
    "\n",
    "mse_base = mean_squared_error(y_test, base_model.predict(X_test))\n",
    "mae_base = mean_absolute_error(y_test, base_model.predict(X_test))\n",
    "\n",
    "print(f\"Base model metrics: \\nmse {mse_base:.2f},\\nmae {mae_base:.2f}\")\n",
    "\n",
    "best_model = base_model\n",
    "best_mse = mse_base"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply feature engineering \n",
    "\n",
    "Use PolynomialFeatures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select the best model, fine tune model 2\n",
    "\n",
    "\n",
    "`degree = 3` is the best for this case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mses_base = []\n",
    "maes_base = []\n",
    "\n",
    "for i in range(1, 6):\n",
    "    model_2 = Pipeline([\n",
    "        (\"pf\", PolynomialFeatures(degree=i)),\n",
    "        (\"lr\", LinearRegression())\n",
    "    ])\n",
    "\n",
    "    model_2.fit(X_train, y_train)\n",
    "    mses_base.append(mean_squared_error(y_test, model_2.predict(X_test)))\n",
    "    maes_base.append(mean_absolute_error(y_test, model_2.predict(X_test)))\n",
    "\n",
    "plt.plot([i for i in range(1, 5)], mses_base[:4], \"go--\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minMse = np.min(mses_base)\n",
    "optDegree = mses_base.index(minMse) + 1\n",
    "print(f\"The optimal degree for Polynomial Features is {optDegree}\")\n",
    "\n",
    "model_2 = Pipeline([\n",
    "    (\"pf\", PolynomialFeatures(degree=optDegree)),\n",
    "    (\"lr\", LinearRegression())\n",
    "])\n",
    "\n",
    "model_2.fit(X_train, y_train)\n",
    "mse_model2 = mean_squared_error(y_test, model_2.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"MSE: {mse_model2}\")\n",
    "if(best_mse > mse_model2):\n",
    "    print(\"Model_2 is better than Model_Base\")\n",
    "    best_model = model_2\n",
    "    best_mse = mse_model2\n",
    "else:\n",
    "    print(\"Model_Base is better\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select the best model, fine tune model 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = cali.drop([labelName], axis=1)\n",
    "y = cali[labelName]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(numericFeatures.columns)\n",
    "\n",
    "print()\n",
    "\n",
    "print(ocean_proximity_category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformFeatures = make_column_transformer(\n",
    "    (PolynomialFeatures(degree=3), numericFeatures.columns),\n",
    "    (OrdinalEncoder(categories=ocean_proximity_category), [\"ocean_proximity\"])\n",
    ")\n",
    "\n",
    "model_3 = Pipeline([\n",
    "    (\"transform\", transformFeatures),\n",
    "    (\"lr\", LinearRegression())\n",
    "])\n",
    "\n",
    "print(model_3)\n",
    "\n",
    "model_3.fit(X_train, y_train)\n",
    "\n",
    "mse_model_3 = mean_squared_error(y_test, model_3.predict(X_test))\n",
    "\n",
    "print(f\"MSE: {mse_model_3}\")\n",
    "if(best_mse > mse_model_3):\n",
    "    print(\"Model_3 is better than Model_Base\")\n",
    "    best_model = model_3\n",
    "    best_mse = mse_model_3\n",
    "else:\n",
    "    print(\"No imporvement\")\n",
    "# print(mean_absolute_error(y_test, model_3.predict(X_test)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select the best model, fine tune model 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformFeatures = make_column_transformer(\n",
    "    (OrdinalEncoder(categories=ocean_proximity_category), [\"ocean_proximity\"])\n",
    ")\n",
    "\n",
    "model_4 = Pipeline([\n",
    "    (\"transform\", transformFeatures),\n",
    "    (\"lr\", LinearRegression())\n",
    "])\n",
    "\n",
    "print(model_4)\n",
    "\n",
    "model_4.fit(X_train, y_train)\n",
    "\n",
    "mse_model_4 = mean_squared_error(y_test, model_4.predict(X_test))\n",
    "\n",
    "print(f\"MSE: {mse_model_4}\")\n",
    "\n",
    "if(best_mse > mse_model_4):\n",
    "    print(\"Model_4 is better than Model_Base\")\n",
    "    best_model = model_4\n",
    "    best_mse = mse_model_4\n",
    "else:\n",
    "    print(\"No imporvement\")\n",
    "# print(mean_absolute_error(y_test, model_3.predict(X_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(best_model)\n",
    "print(best_mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## interpret the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_base = cali[numericFeatures.columns]\n",
    "y_base = cali[labelName]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_base, y_base, test_size=0.3, random_state=1234)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.inspection import permutation_importance\n",
    "r = permutation_importance(best_model, X_test, y_test,\n",
    "                           n_repeats=30,\n",
    "                           random_state=0)\n",
    "\n",
    "for i in r.importances_mean.argsort()[::-1]:\n",
    "    if r.importances_mean[i] - 2 * r.importances_std[i] > 0:\n",
    "        print(f\"{X_test.columns[i]:<8}\\t\\t\"\n",
    "              f\"{r.importances_mean[i]:.3f}\\t\\t\"\n",
    "              f\" +/- {r.importances_std[i]:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use Interpret ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from interpret import set_visualize_provider\n",
    "from interpret.provider import InlineProvider\n",
    "set_visualize_provider(InlineProvider())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_4[\"transform\"].fit_transform(X_train)\n",
    "X_train_transform = pd.DataFrame(model_2[\"pf\"].transform(X_train), columns=model_2[\"pf\"].get_feature_names_out())\n",
    "X_test_transform = pd.DataFrame(model_2[\"pf\"].transform(X_test), columns=model_2[\"pf\"].get_feature_names_out())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train_transform.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from interpret.glassbox import LinearRegression\n",
    "from interpret import show\n",
    "\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train_transform, y_train)\n",
    "\n",
    "lr_global = lr.explain_global()\n",
    "show(lr_global)\n",
    "\n",
    "lr_local = lr.explain_local(X_test_transform[:5], y_train[:5])\n",
    "show(lr_local)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "### The best model is:\n",
    "\n",
    "- LinearRegression\n",
    "- Preprosessing on numerical features using PolynominalFeature function\n",
    "- No categorical feature was used\n",
    "\n",
    "```text\n",
    "Pipeline(steps=[('pf', PolynomialFeatures(degree=3)),\n",
    "                ('lr', LinearRegression())])\n",
    "\n",
    "MSE: 3733457854.427122\n",
    "```\n",
    "\n",
    "### The most important features are:\n",
    "- households\n",
    "- total_bestrooms\n",
    "- total_rooms\n",
    "- population\n",
    "- latitude\n",
    "- longitude\n",
    "- median_income"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('pcmlai')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "a9d6e8f0c2c09c92c2b254b369cc204ff0621338c49c8f702dbb905c49fc37e9"
   }
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
